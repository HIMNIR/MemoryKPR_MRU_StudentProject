{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Test Pretrained Inception Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted labels for (1) 18380579401063495.jpg (top-3):\n",
      "1: motor_scooter (90.88%)\n",
      "2: moped (1.75%)\n",
      "3: snowmobile (1.61%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted labels for (1) 18380579401063495.png (top-3):\n",
      "1: motor_scooter (89.87%)\n",
      "2: snowmobile (1.72%)\n",
      "3: moped (1.67%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted labels for (1) @GreyCupFestival - 109th Grey Cup.jpeg (top-3):\n",
      "1: stage (58.90%)\n",
      "2: moving_van (2.70%)\n",
      "3: mortarboard (1.68%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Predicted labels for (10) 17887803224903630.jpeg (top-3):\n",
      "1: seashore (39.63%)\n",
      "2: sandbar (7.99%)\n",
      "3: Eskimo_dog (3.33%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Predicted labels for (11) 17997439897932301.png (top-3):\n",
      "1: crash_helmet (60.60%)\n",
      "2: motor_scooter (5.71%)\n",
      "3: moped (3.50%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted labels for (12) 17985809330117499.jpeg (top-3):\n",
      "1: moped (63.87%)\n",
      "2: motor_scooter (16.93%)\n",
      "3: crash_helmet (8.56%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted labels for (13) 18013990822817757.jpeg (top-3):\n",
      "1: jersey (50.91%)\n",
      "2: mailbag (3.02%)\n",
      "3: Christmas_stocking (2.67%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Predicted labels for (14) 17993584322154200.jpeg (top-3):\n",
      "1: cliff (27.65%)\n",
      "2: fountain (6.66%)\n",
      "3: ski (5.71%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Predicted labels for (15) 18346855723078911.jpeg (top-3):\n",
      "1: street_sign (22.71%)\n",
      "2: scoreboard (14.95%)\n",
      "3: packet (5.16%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted labels for (16) 18379894042056715.jpeg (top-3):\n",
      "1: cowboy_hat (19.28%)\n",
      "2: shower_cap (18.05%)\n",
      "3: cowboy_boot (3.09%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Predicted labels for (17) 17876557646942156.jpeg (top-3):\n",
      "1: football_helmet (63.30%)\n",
      "2: ballplayer (1.76%)\n",
      "3: bathing_cap (1.68%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Predicted labels for (18) 17956303754673865.jpeg (top-3):\n",
      "1: football_helmet (48.31%)\n",
      "2: ballplayer (9.04%)\n",
      "3: baseball (2.34%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Predicted labels for (19) 18027245935589987.jpeg (top-3):\n",
      "1: book_jacket (79.81%)\n",
      "2: comic_book (3.82%)\n",
      "3: ski (2.78%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Predicted labels for (2) 18040499875507660.jpeg (top-3):\n",
      "1: ski (74.65%)\n",
      "2: puck (4.28%)\n",
      "3: ski_mask (2.52%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Predicted labels for (2) @VanArchives - Vancouver Archives.jpeg (top-3):\n",
      "1: mortarboard (30.68%)\n",
      "2: academic_gown (6.63%)\n",
      "3: groom (4.23%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted labels for (2) ball-park-brand-mflmvznfdq8-unsplash.jpeg (top-3):\n",
      "1: conch (27.10%)\n",
      "2: torch (14.17%)\n",
      "3: wok (5.40%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Predicted labels for (3) 18005670805793076.jpeg (top-3):\n",
      "1: moped (65.07%)\n",
      "2: crash_helmet (27.53%)\n",
      "3: motor_scooter (3.97%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Predicted labels for (3) @NewEraCanada - New Era Canada.jpeg (top-3):\n",
      "1: jersey (16.18%)\n",
      "2: comic_book (14.81%)\n",
      "3: pickelhaube (4.00%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Predicted labels for (4) 17978197394393810.jpeg (top-3):\n",
      "1: motor_scooter (68.36%)\n",
      "2: moped (28.41%)\n",
      "3: crash_helmet (0.36%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Predicted labels for (4) @betregal - BetRegal.jpeg (top-3):\n",
      "1: web_site (70.63%)\n",
      "2: street_sign (2.32%)\n",
      "3: analog_clock (1.63%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Predicted labels for (5) 18262020151093596.png (top-3):\n",
      "1: crash_helmet (69.02%)\n",
      "2: moped (10.14%)\n",
      "3: motor_scooter (9.70%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Predicted labels for (5) @Stats_Junkie - Chris 🇨🇦🏈 Stats Junkie.png (top-3):\n",
      "1: menu (88.63%)\n",
      "2: web_site (1.05%)\n",
      "3: shower_curtain (0.27%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Predicted labels for (6) 18030065674525036.jpeg (top-3):\n",
      "1: web_site (68.65%)\n",
      "2: menu (6.07%)\n",
      "3: slot (0.54%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted labels for (6) @Tara_Marie29 - Tara-Marie Hall.jpeg (top-3):\n",
      "1: basketball (80.41%)\n",
      "2: rugby_ball (8.90%)\n",
      "3: punching_bag (1.81%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Predicted labels for (7) 18006556474787720.png (top-3):\n",
      "1: moped (83.99%)\n",
      "2: crash_helmet (3.17%)\n",
      "3: motor_scooter (2.71%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Predicted labels for (7) @Cdn_Turkey - Canadian Turkey.jpeg (top-3):\n",
      "1: soup_bowl (20.95%)\n",
      "2: plate (17.46%)\n",
      "3: guacamole (8.70%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Predicted labels for (8) 17963380910618789.jpeg (top-3):\n",
      "1: rapeseed (23.73%)\n",
      "2: sandbar (12.63%)\n",
      "3: dam (5.48%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Predicted labels for (8) @fisherwavy - Fisher Wavy.jpeg (top-3):\n",
      "1: web_site (85.94%)\n",
      "2: harvester (0.27%)\n",
      "3: printer (0.22%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Predicted labels for (9) 17895815912854630.png (top-3):\n",
      "1: crash_helmet (37.81%)\n",
      "2: disk_brake (5.77%)\n",
      "3: mountain_bike (5.51%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Predicted labels for IMG_0866 Large.jpeg (top-3):\n",
      "1: stage (53.45%)\n",
      "2: cinema (19.19%)\n",
      "3: scoreboard (12.39%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Predicted labels for IMG_2318 Large.jpeg (top-3):\n",
      "1: restaurant (42.27%)\n",
      "2: stage (20.24%)\n",
      "3: butcher_shop (7.42%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted labels for IMG_2334 Large.jpeg (top-3):\n",
      "1: dome (52.53%)\n",
      "2: palace (7.47%)\n",
      "3: cinema (3.96%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted labels for IMG_2345 Large.jpeg (top-3):\n",
      "1: stage (9.04%)\n",
      "2: jigsaw_puzzle (8.76%)\n",
      "3: grand_piano (5.27%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Predicted labels for IMG_3155.JPG (top-3):\n",
      "1: park_bench (3.52%)\n",
      "2: limousine (2.55%)\n",
      "3: abaya (2.07%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Predicted labels for IMG_3386 Large.jpeg (top-3):\n",
      "1: freight_car (71.37%)\n",
      "2: submarine (9.20%)\n",
      "3: breakwater (3.24%)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Predicted labels for IMG_3614 Large.jpeg (top-3):\n",
      "1: patio (34.88%)\n",
      "2: thatch (12.06%)\n",
      "3: lakeside (6.05%)\n",
      "\n",
      "Filename: (1) 18380579401063495.jpg\n",
      "Predicted labels (top-3):\n",
      "1: motor_scooter (90.88%)\n",
      "2: moped (1.75%)\n",
      "3: snowmobile (1.61%)\n",
      "\n",
      "Filename: (1) 18380579401063495.png\n",
      "Predicted labels (top-3):\n",
      "1: motor_scooter (89.87%)\n",
      "2: snowmobile (1.72%)\n",
      "3: moped (1.67%)\n",
      "\n",
      "Filename: (1) @GreyCupFestival - 109th Grey Cup.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: stage (58.90%)\n",
      "2: moving_van (2.70%)\n",
      "3: mortarboard (1.68%)\n",
      "\n",
      "Filename: (10) 17887803224903630.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: seashore (39.63%)\n",
      "2: sandbar (7.99%)\n",
      "3: Eskimo_dog (3.33%)\n",
      "\n",
      "Filename: (11) 17997439897932301.png\n",
      "Predicted labels (top-3):\n",
      "1: crash_helmet (60.60%)\n",
      "2: motor_scooter (5.71%)\n",
      "3: moped (3.50%)\n",
      "\n",
      "Filename: (12) 17985809330117499.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: moped (63.87%)\n",
      "2: motor_scooter (16.93%)\n",
      "3: crash_helmet (8.56%)\n",
      "\n",
      "Filename: (13) 18013990822817757.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: jersey (50.91%)\n",
      "2: mailbag (3.02%)\n",
      "3: Christmas_stocking (2.67%)\n",
      "\n",
      "Filename: (14) 17993584322154200.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: cliff (27.65%)\n",
      "2: fountain (6.66%)\n",
      "3: ski (5.71%)\n",
      "\n",
      "Filename: (15) 18346855723078911.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: street_sign (22.71%)\n",
      "2: scoreboard (14.95%)\n",
      "3: packet (5.16%)\n",
      "\n",
      "Filename: (16) 18379894042056715.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: cowboy_hat (19.28%)\n",
      "2: shower_cap (18.05%)\n",
      "3: cowboy_boot (3.09%)\n",
      "\n",
      "Filename: (17) 17876557646942156.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: football_helmet (63.30%)\n",
      "2: ballplayer (1.76%)\n",
      "3: bathing_cap (1.68%)\n",
      "\n",
      "Filename: (18) 17956303754673865.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: football_helmet (48.31%)\n",
      "2: ballplayer (9.04%)\n",
      "3: baseball (2.34%)\n",
      "\n",
      "Filename: (19) 18027245935589987.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: book_jacket (79.81%)\n",
      "2: comic_book (3.82%)\n",
      "3: ski (2.78%)\n",
      "\n",
      "Filename: (2) 18040499875507660.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: ski (74.65%)\n",
      "2: puck (4.28%)\n",
      "3: ski_mask (2.52%)\n",
      "\n",
      "Filename: (2) @VanArchives - Vancouver Archives.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: mortarboard (30.68%)\n",
      "2: academic_gown (6.63%)\n",
      "3: groom (4.23%)\n",
      "\n",
      "Filename: (2) ball-park-brand-mflmvznfdq8-unsplash.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: conch (27.10%)\n",
      "2: torch (14.17%)\n",
      "3: wok (5.40%)\n",
      "\n",
      "Filename: (3) 18005670805793076.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: moped (65.07%)\n",
      "2: crash_helmet (27.53%)\n",
      "3: motor_scooter (3.97%)\n",
      "\n",
      "Filename: (3) @NewEraCanada - New Era Canada.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: jersey (16.18%)\n",
      "2: comic_book (14.81%)\n",
      "3: pickelhaube (4.00%)\n",
      "\n",
      "Filename: (4) 17978197394393810.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: motor_scooter (68.36%)\n",
      "2: moped (28.41%)\n",
      "3: crash_helmet (0.36%)\n",
      "\n",
      "Filename: (4) @betregal - BetRegal.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: web_site (70.63%)\n",
      "2: street_sign (2.32%)\n",
      "3: analog_clock (1.63%)\n",
      "\n",
      "Filename: (5) 18262020151093596.png\n",
      "Predicted labels (top-3):\n",
      "1: crash_helmet (69.02%)\n",
      "2: moped (10.14%)\n",
      "3: motor_scooter (9.70%)\n",
      "\n",
      "Filename: (5) @Stats_Junkie - Chris 🇨🇦🏈 Stats Junkie.png\n",
      "Predicted labels (top-3):\n",
      "1: menu (88.63%)\n",
      "2: web_site (1.05%)\n",
      "3: shower_curtain (0.27%)\n",
      "\n",
      "Filename: (6) 18030065674525036.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: web_site (68.65%)\n",
      "2: menu (6.07%)\n",
      "3: slot (0.54%)\n",
      "\n",
      "Filename: (6) @Tara_Marie29 - Tara-Marie Hall.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: basketball (80.41%)\n",
      "2: rugby_ball (8.90%)\n",
      "3: punching_bag (1.81%)\n",
      "\n",
      "Filename: (7) 18006556474787720.png\n",
      "Predicted labels (top-3):\n",
      "1: moped (83.99%)\n",
      "2: crash_helmet (3.17%)\n",
      "3: motor_scooter (2.71%)\n",
      "\n",
      "Filename: (7) @Cdn_Turkey - Canadian Turkey.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: soup_bowl (20.95%)\n",
      "2: plate (17.46%)\n",
      "3: guacamole (8.70%)\n",
      "\n",
      "Filename: (8) 17963380910618789.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: rapeseed (23.73%)\n",
      "2: sandbar (12.63%)\n",
      "3: dam (5.48%)\n",
      "\n",
      "Filename: (8) @fisherwavy - Fisher Wavy.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: web_site (85.94%)\n",
      "2: harvester (0.27%)\n",
      "3: printer (0.22%)\n",
      "\n",
      "Filename: (9) 17895815912854630.png\n",
      "Predicted labels (top-3):\n",
      "1: crash_helmet (37.81%)\n",
      "2: disk_brake (5.77%)\n",
      "3: mountain_bike (5.51%)\n",
      "\n",
      "Filename: IMG_0866 Large.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: stage (53.45%)\n",
      "2: cinema (19.19%)\n",
      "3: scoreboard (12.39%)\n",
      "\n",
      "Filename: IMG_2318 Large.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: restaurant (42.27%)\n",
      "2: stage (20.24%)\n",
      "3: butcher_shop (7.42%)\n",
      "\n",
      "Filename: IMG_2334 Large.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: dome (52.53%)\n",
      "2: palace (7.47%)\n",
      "3: cinema (3.96%)\n",
      "\n",
      "Filename: IMG_2345 Large.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: stage (9.04%)\n",
      "2: jigsaw_puzzle (8.76%)\n",
      "3: grand_piano (5.27%)\n",
      "\n",
      "Filename: IMG_3155.JPG\n",
      "Predicted labels (top-3):\n",
      "1: park_bench (3.52%)\n",
      "2: limousine (2.55%)\n",
      "3: abaya (2.07%)\n",
      "\n",
      "Filename: IMG_3386 Large.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: freight_car (71.37%)\n",
      "2: submarine (9.20%)\n",
      "3: breakwater (3.24%)\n",
      "\n",
      "Filename: IMG_3614 Large.jpeg\n",
      "Predicted labels (top-3):\n",
      "1: patio (34.88%)\n",
      "2: thatch (12.06%)\n",
      "3: lakeside (6.05%)\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained InceptionV3 model\n",
    "model = InceptionV3(weights='imagenet')\n",
    "\n",
    "# Function to preprocess the image and predict its label\n",
    "def predict_image_label(img_path):\n",
    "    # Load the image file, resizing it to 299x299 pixels (as required by InceptionV3)\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    \n",
    "    # Convert the image to a numpy array and add an additional dimension (for batch size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Preprocess the image for the InceptionV3 model\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    # Predict the probabilities across all output classes\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    # Decode the predictions to get human-readable labels\n",
    "    decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "    predictions_list = []\n",
    "    print(f\"Predicted labels for {os.path.basename(img_path)} (top-3):\")\n",
    "    for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "        print(f\"{i+1}: {label} ({score*100:.2f}%)\")\n",
    "        predictions_list.append((label, score))\n",
    "    return predictions_list\n",
    "\n",
    "# Path to the folder containing images\n",
    "folder_path = 'Example Data-20240208T214429Z-001/Example Data/exported'\n",
    "\n",
    "predictions_dict = {}\n",
    "# Iterate over all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):  # Check for common image file extensions\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        predictions_dict[filename] = predict_image_label(img_path)\n",
    "\n",
    "# Print the filenames and corresponding predicted labels\n",
    "for filename, predicted_labels in predictions_dict.items():\n",
    "    print(f\"\\nFilename: {filename}\")\n",
    "    print(\"Predicted labels (top-3):\")\n",
    "    for i, (label, score) in enumerate(predicted_labels):\n",
    "        print(f\"{i+1}: {label} ({score*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocces the images in the images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    try:\n",
    "        # Load the image file, resizing it to 299x299 pixels (as required by InceptionV3)\n",
    "        img = image.load_img(img_path, target_size=(299, 299))\n",
    "        \n",
    "        # Convert the image to a numpy array\n",
    "        img_array = image.img_to_array(img)\n",
    "        \n",
    "        # Add a dimension to the array for batch size\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        # Apply the specific preprocessing required by InceptionV3\n",
    "        img_array = preprocess_input(img_array)\n",
    "        \n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_in_folder(folder_path):\n",
    "    preprocessed_images = []\n",
    "    \n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):  # Check for common image file extensions\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img_array = preprocess_image(img_path)\n",
    "            if img_array is not None:\n",
    "                preprocessed_images.append(img_array)\n",
    "    \n",
    "    return preprocessed_images\n",
    "\n",
    "# Preprocess all images in the specified folder\n",
    "preprocessed_images = preprocess_images_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the image labels from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = 'Example Data-20240208T214429Z-001/Example Data/Imagelabels.xlsx'\n",
    "\n",
    "\n",
    "# Function to read the Excel file and extract image names and labels\n",
    "def read_labels_from_excel(excel_path):\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(excel_path)\n",
    "    \n",
    "    # the Excel file has columns 'Image Name' and 'Label'\n",
    "    labels_dict = pd.Series(df.Label.values, index=df['Image Name']).to_dict()\n",
    "    \n",
    "    return labels_dict\n",
    "\n",
    "# Call the function and store the result in a variable\n",
    "actual_labels_dict = read_labels_from_excel(excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "(1) @GreyCupFestival - 109th Grey Cup.jpeg: Predicted Label - stage, Actual Label - Glasses, Similarity - 33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "(10) 17887803224903630.jpeg: Predicted Label - seashore, Actual Label - Woman, Similarity - 15%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "(12) 17985809330117499.jpeg: Predicted Label - moped, Actual Label - Night, Similarity - 0%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "(13) 18013990822817757.jpeg: Predicted Label - jersey, Actual Label - Paper, Similarity - 36%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "(14) 17993584322154200.jpeg: Predicted Label - cliff, Actual Label - Lion, Similarity - 44%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "(15) 18346855723078911.jpeg: Predicted Label - street_sign, Actual Label - Poster, Similarity - 35%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "(16) 18379894042056715.jpeg: Predicted Label - cowboy_hat, Actual Label - Head, Similarity - 29%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "(17) 17876557646942156.jpeg: Predicted Label - football_helmet, Actual Label - Hand, Similarity - 11%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "(18) 17956303754673865.jpeg: Predicted Label - football_helmet, Actual Label - People, Similarity - 29%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "(19) 18027245935589987.jpeg: Predicted Label - book_jacket, Actual Label - People, Similarity - 24%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "(2) 18040499875507660.jpeg: Predicted Label - ski, Actual Label - Helmet, Similarity - 0%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "(2) @VanArchives - Vancouver Archives.jpeg: Predicted Label - mortarboard, Actual Label - Audience, Similarity - 21%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "(2) ball-park-brand-mflmvznfdq8-unsplash.jpeg: Predicted Label - conch, Actual Label - Shoe, Similarity - 22%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "(3) 18005670805793076.jpeg: Predicted Label - moped, Actual Label - Car Wheel, Similarity - 14%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "(3) @NewEraCanada - New Era Canada.jpeg: Predicted Label - jersey, Actual Label - QR Code, Similarity - 15%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "(4) 17978197394393810.jpeg: Predicted Label - motor_scooter, Actual Label - Shoe, Similarity - 24%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "(4) @betregal - BetRegal.jpeg: Predicted Label - web_site, Actual Label - Text, Similarity - 33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "(5) @Stats_Junkie - Chris 🇨🇦🏈 Stats Junkie.png: Predicted Label - menu, Actual Label - Measurements, Similarity - 38%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "(6) 18030065674525036.jpeg: Predicted Label - web_site, Actual Label - Poster, Similarity - 43%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "(6) @Tara_Marie29 - Tara-Marie Hall.jpeg: Predicted Label - basketball, Actual Label - T-Shirt, Similarity - 24%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "(7) @Cdn_Turkey - Canadian Turkey.jpeg: Predicted Label - soup_bowl, Actual Label - Pancake, Similarity - 12%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "(8) 17963380910618789.jpeg: Predicted Label - rapeseed, Actual Label - Bird, Similarity - 33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "(8) @fisherwavy - Fisher Wavy.jpeg: Predicted Label - web_site, Actual Label - Appliance, Similarity - 12%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "IMG_0866 Large.jpeg: Predicted Label - stage, Actual Label - Outdoors, Similarity - 15%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "IMG_2318 Large.jpeg: Predicted Label - restaurant, Actual Label - Audience, Similarity - 33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "IMG_2334 Large.jpeg: Predicted Label - dome, Actual Label - Urban, Similarity - 0%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "IMG_2345 Large.jpeg: Predicted Label - stage, Actual Label - Head, Similarity - 22%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "IMG_3155.JPG: Predicted Label - park_bench, Actual Label - Shoe, Similarity - 14%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "IMG_3386 Large.jpeg: Predicted Label - freight_car, Actual Label - Airliner, Similarity - 32%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "IMG_3614 Large.jpeg: Predicted Label - patio, Actual Label - Rural, Similarity - 20%\n",
      "Average Label Similarity: 22.766666666666666%\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(img_path):\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(299, 299))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_image_label(img_path):\n",
    "    img_array = preprocess_image(img_path)\n",
    "    if img_array is not None:\n",
    "        predictions = model.predict(img_array)\n",
    "        decoded_predictions = decode_predictions(predictions, top=1)[0]\n",
    "        return decoded_predictions[0][1]  # Return only the top prediction label\n",
    "    return None\n",
    "\n",
    "def read_labels_from_excel(excel_path):\n",
    "    df = pd.read_excel(excel_path)\n",
    "    labels_dict = pd.Series(df.Label.values, index=df['Image Name']).to_dict()\n",
    "    return labels_dict\n",
    "\n",
    "# Function to compare predicted and actual labels for similarity\n",
    "def compare_label_similarity(predicted_label, actual_label):\n",
    "    return fuzz.ratio(predicted_label.lower(), actual_label.lower())\n",
    "\n",
    "# Main processing function\n",
    "def process_images_and_compare_labels(folder_path, excel_path):\n",
    "    actual_labels_dict = read_labels_from_excel(excel_path)\n",
    "    similarities = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            predicted_label = predict_image_label(img_path)\n",
    "            actual_label = actual_labels_dict.get(filename)\n",
    "\n",
    "            if predicted_label and actual_label:\n",
    "                similarity_score = compare_label_similarity(predicted_label, actual_label)\n",
    "                similarities.append(similarity_score)\n",
    "                print(f\"{filename}: Predicted Label - {predicted_label}, Actual Label - {actual_label}, Similarity - {similarity_score}%\")\n",
    "\n",
    "    if similarities:\n",
    "        average_similarity = sum(similarities) / len(similarities)\n",
    "        print(f\"Average Label Similarity: {average_similarity}%\")\n",
    "    else:\n",
    "        print(\"No images processed.\")\n",
    "\n",
    "# Update with your actual folder and Excel paths\n",
    "folder_path = 'Example Data-20240208T214429Z-001/Example Data/exported'\n",
    "excel_path = 'Example Data-20240208T214429Z-001/Example Data/Imagelabels.xlsx'\n",
    "\n",
    "process_images_and_compare_labels(folder_path, excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "(1) @GreyCupFestival - 109th Grey Cup.jpeg: Predicted - stage, Actual - Glasses, Similarity - 33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "(10) 17887803224903630.jpeg: Predicted - seashore, Actual - Woman, Similarity - 15%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "(12) 17985809330117499.jpeg: Predicted - moped, Actual - Night, Similarity - 0%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "(13) 18013990822817757.jpeg: Predicted - jersey, Actual - Paper, Similarity - 36%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "(14) 17993584322154200.jpeg: Predicted - cliff, Actual - Lion, Similarity - 44%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "(15) 18346855723078911.jpeg: Predicted - street_sign, Actual - Poster, Similarity - 35%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "(16) 18379894042056715.jpeg: Predicted - cowboy_hat, Actual - Head, Similarity - 29%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "(17) 17876557646942156.jpeg: Predicted - football_helmet, Actual - Hand, Similarity - 11%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "(18) 17956303754673865.jpeg: Predicted - football_helmet, Actual - People, Similarity - 29%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "(19) 18027245935589987.jpeg: Predicted - book_jacket, Actual - People, Similarity - 24%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "(2) 18040499875507660.jpeg: Predicted - ski, Actual - Helmet, Similarity - 0%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "(2) @VanArchives - Vancouver Archives.jpeg: Predicted - mortarboard, Actual - Audience, Similarity - 21%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "(2) ball-park-brand-mflmvznfdq8-unsplash.jpeg: Predicted - conch, Actual - Shoe, Similarity - 22%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "(3) 18005670805793076.jpeg: Predicted - moped, Actual - Car Wheel, Similarity - 14%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "(3) @NewEraCanada - New Era Canada.jpeg: Predicted - jersey, Actual - QR Code, Similarity - 15%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "(4) 17978197394393810.jpeg: Predicted - motor_scooter, Actual - Shoe, Similarity - 24%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "(4) @betregal - BetRegal.jpeg: Predicted - web_site, Actual - Text, Similarity - 33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "(5) @Stats_Junkie - Chris 🇨🇦🏈 Stats Junkie.png: Predicted - menu, Actual - Measurements, Similarity - 38%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "(6) 18030065674525036.jpeg: Predicted - web_site, Actual - Poster, Similarity - 43%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "(6) @Tara_Marie29 - Tara-Marie Hall.jpeg: Predicted - basketball, Actual - T-Shirt, Similarity - 24%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "(7) @Cdn_Turkey - Canadian Turkey.jpeg: Predicted - soup_bowl, Actual - Pancake, Similarity - 12%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "(8) 17963380910618789.jpeg: Predicted - rapeseed, Actual - Bird, Similarity - 33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "(8) @fisherwavy - Fisher Wavy.jpeg: Predicted - web_site, Actual - Appliance, Similarity - 12%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "IMG_0866 Large.jpeg: Predicted - stage, Actual - Outdoors, Similarity - 15%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "IMG_2318 Large.jpeg: Predicted - restaurant, Actual - Audience, Similarity - 33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "IMG_2334 Large.jpeg: Predicted - dome, Actual - Urban, Similarity - 0%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "IMG_2345 Large.jpeg: Predicted - stage, Actual - Head, Similarity - 22%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "IMG_3155.JPG: Predicted - park_bench, Actual - Shoe, Similarity - 14%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "IMG_3386 Large.jpeg: Predicted - freight_car, Actual - Airliner, Similarity - 32%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "IMG_3614 Large.jpeg: Predicted - patio, Actual - Rural, Similarity - 20%\n",
      "\n",
      "Average Label Similarity: 22.766666666666666%\n",
      "The system does not meet the required similarity threshold of 80%. System evaluation failed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main processing and evaluation function\n",
    "def evaluate_image_labeling_system(folder_path, excel_path, similarity_threshold=80):\n",
    "    actual_labels_dict = read_labels_from_excel(excel_path)\n",
    "    similarities = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            predicted_label = predict_image_label(img_path)\n",
    "            actual_label = actual_labels_dict.get(filename)\n",
    "\n",
    "            if predicted_label and actual_label:\n",
    "                similarity_score = compare_label_similarity(predicted_label, actual_label)\n",
    "                similarities.append(similarity_score)\n",
    "                print(f\"{filename}: Predicted - {predicted_label}, Actual - {actual_label}, Similarity - {similarity_score}%\")\n",
    "\n",
    "    if similarities:\n",
    "        average_similarity = sum(similarities) / len(similarities)\n",
    "        print(f\"\\nAverage Label Similarity: {average_similarity}%\")\n",
    "        \n",
    "        if average_similarity >= similarity_threshold:\n",
    "            print(f\"The system meets the required similarity threshold of {similarity_threshold}%. System evaluation passed.\")\n",
    "        else:\n",
    "            print(f\"The system does not meet the required similarity threshold of {similarity_threshold}%. System evaluation failed.\")\n",
    "    else:\n",
    "        print(\"No images processed. Evaluation cannot be performed.\")\n",
    "\n",
    "\n",
    "evaluate_image_labeling_system(folder_path, excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune the pretrained model to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "If class_mode=\"binary\", y_col=\"Label\" column values must be strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m val_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(preprocessing_function\u001b[38;5;241m=\u001b[39mpreprocess_input)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Prepare the training and validation generators\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImage Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m299\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m299\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m val_datagen\u001b[38;5;241m.\u001b[39mflow_from_dataframe(\n\u001b[0;32m     53\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mval_df,\n\u001b[0;32m     54\u001b[0m     x_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage Name\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     58\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1208\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[1;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m   1202\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1205\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1206\u001b[0m     )\n\u001b[1;32m-> 1208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_filenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:751\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    750\u001b[0m \u001b[38;5;66;03m# check that inputs match the required class_mode\u001b[39;00m\n\u001b[1;32m--> 751\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    753\u001b[0m     validate_filenames\n\u001b[0;32m    754\u001b[0m ):  \u001b[38;5;66;03m# check which image files are valid and keep them\u001b[39;00m\n\u001b[0;32m    755\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_valid_filepaths(df, x_col)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:819\u001b[0m, in \u001b[0;36mDataFrameIterator._check_params\u001b[1;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(df[y_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m))):\n\u001b[1;32m--> 819\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    820\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf class_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, y_col=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m column \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    821\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues must be strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mode, y_col)\n\u001b[0;32m    822\u001b[0m         )\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# check that if binary there are only 2 different classes\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: If class_mode=\"binary\", y_col=\"Label\" column values must be strings."
     ]
    }
   ],
   "source": [
    "# Load the pre-trained InceptionV3 model without the top layer\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add new layers for fine-tuning\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # New FC layer, output dim=1024\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # New softmax layer for classification\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze all layers in the base InceptionV3 model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Prepare data for training\n",
    "excel_path = 'Example Data-20240208T214429Z-001/Example Data/Imagelabels.xlsx'\n",
    "df = pd.read_excel(excel_path)\n",
    "df['Image Name'] = df['Image Name'].apply(lambda x: os.path.join('Example Data-20240208T214429Z-001/Example Data/exported', x))\n",
    "\n",
    "# Assuming binary classification for simplicity, adjust as needed\n",
    "df['Label'] = df['Label'].apply(lambda x: 1 if x == 'YourPositiveClass' else 0)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df = df.sample(frac=0.8, random_state=200)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "# Data augmentation for training images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Prepare the training and validation generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Image Name',\n",
    "    y_col='Label',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Image Name',\n",
    "    y_col='Label',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,  # Start with a few epochs; increase as needed\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
